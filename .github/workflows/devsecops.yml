name: Web3 DevSecOps Bug Bounty Audit

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    - cron: '0 2 * * 1'  # Weekly runs on Monday 2 AM
  workflow_dispatch:     # Manual trigger

env:
  FOUNDRY_PROFILE: ci

jobs:
  audit:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
    - name: Checkout repo
      uses: actions/checkout@v4
      with:
        submodules: recursive

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install Foundry
      uses: foundry-rs/foundry-toolchain@v1

    - name: Create reports directory
      run: mkdir -p reports

    - name: Install dependencies
      run: |
        npm install --save-dev hardhat @nomicfoundation/hardhat-toolbox
        pip install slither-analyzer mythril echidna-parade solc-select web3 requests

    - name: Setup Solidity compiler
      run: |
        solc-select install 0.8.19
        solc-select use 0.8.19

    - name: Advanced Static Analysis Setup
      run: |
        echo "ğŸ”§ Setting up advanced analysis tools..."
        
        # Install additional tools for comprehensive analysis
        pip install manticore[native] crytic-compile
        npm install -g solhint @crytic/echidna surya
        
        # Download latest vulnerability databases
        mkdir -p databases
        wget -O databases/swc-registry.json https://swcregistry.io/api/registry || echo "SWC registry unavailable"
        
        # Setup custom detectors
        mkdir -p custom_detectors
        cat > custom_detectors/high_value_detectors.py << 'EOF'
        from slither.detectors.abstract_detector import AbstractDetector, DetectorClassification
        from slither.core.declarations import Function

        class HighValueVulnerabilityDetector(AbstractDetector):
            """
            Custom detector for high-value vulnerabilities specifically targeting bug bounty programs
            """
            
            ARGUMENT = "high-value-bugs"
            HELP = "Detect high-value vulnerabilities for bug bounty"
            IMPACT = DetectorClassification.HIGH
            CONFIDENCE = DetectorClassification.HIGH

            def _detect(self):
                results = []
                
                for contract in self.compilation_unit.contracts_derived:
                    for function in contract.functions:
                        # Look for flash loan attack vectors
                        if any(keyword in function.name.lower() for keyword in ['flashloan', 'borrow', 'liquidate']):
                            if function.visibility in ['public', 'external']:
                                info = [function, " might be vulnerable to flash loan attacks\n"]
                                results.append(self.generate_result(info))
                        
                        # Look for governance attack vectors  
                        if any(keyword in function.name.lower() for keyword in ['vote', 'propose', 'execute']):
                            if not function.is_protected():
                                info = [function, " governance function lacks proper protection\n"]
                                results.append(self.generate_result(info))
                
                return results
        EOF

    # Security Analysis Tools
    
    - name: Run Slither Analysis with Smart Filtering
      run: |
        echo "ğŸ” Running Slither static analysis with false positive reduction..."
        
        # Run Slither with custom config
        slither . --config-file tools/slither-config.json --json reports/slither-raw.json --sarif reports/slither.sarif || true
        
        # Create intelligent filtering script
        cat > filter_results.py << 'EOF'
        import json
        import re
        
        def is_false_positive(detector):
            """Advanced false positive detection"""
            
            # Skip informational issues in test files
            if 'test/' in detector.get('elements', [{}])[0].get('source_mapping', {}).get('filename', ''):
                if detector.get('impact') in ['Informational', 'Optimization']:
                    return True
            
            # Skip pragma warnings for libraries and interfaces
            if detector.get('check') == 'pragma-version':
                filename = detector.get('elements', [{}])[0].get('source_mapping', {}).get('filename', '')
                if 'interface' in filename.lower() or 'library' in filename.lower():
                    return True
            
            # Skip reentrancy warnings for view/pure functions
            if 'reentrancy' in detector.get('check', ''):
                for element in detector.get('elements', []):
                    if element.get('type') == 'function':
                        if 'view' in element.get('type_specific_fields', {}).get('signature', '') or \
                           'pure' in element.get('type_specific_fields', {}).get('signature', ''):
                            return True
            
            # Skip external-function warnings for interfaces
            if detector.get('check') == 'external-function':
                description = detector.get('description', '')
                if 'interface' in description.lower() or 'abstract' in description.lower():
                    return True
            
            # Skip unused-return for known safe patterns
            if detector.get('check') == 'unused-return':
                description = detector.get('description', '')
                if 'IERC20' in description or 'token.transfer' in description:
                    return True
            
            return False
        
        def confidence_score(detector):
            """Calculate confidence score for findings"""
            base_score = {'High': 0.9, 'Medium': 0.7, 'Low': 0.5, 'Informational': 0.3, 'Optimization': 0.2}
            impact_score = base_score.get(detector.get('impact'), 0.5)
            
            # Boost confidence for critical patterns
            check = detector.get('check', '')
            if check in ['reentrancy-eth', 'suicidal', 'arbitrary-send', 'controlled-delegatecall']:
                impact_score += 0.1
            
            # Reduce confidence for commonly misunderstood patterns
            if check in ['low-level-calls', 'assembly', 'pragma-version']:
                impact_score -= 0.2
            
            return min(1.0, max(0.0, impact_score))
        
        # Load and filter results
        try:
            with open('reports/slither-raw.json', 'r') as f:
                data = json.load(f)
            
            if 'results' in data and 'detectors' in data['results']:
                original_count = len(data['results']['detectors'])
                
                # Filter false positives and add confidence scores
                filtered_detectors = []
                for detector in data['results']['detectors']:
                    if not is_false_positive(detector):
                        detector['confidence_score'] = confidence_score(detector)
                        filtered_detectors.append(detector)
                
                data['results']['detectors'] = filtered_detectors
                filtered_count = len(filtered_detectors)
                
                # Sort by impact and confidence
                impact_order = {'Critical': 4, 'High': 3, 'Medium': 2, 'Low': 1, 'Informational': 0, 'Optimization': 0}
                data['results']['detectors'].sort(
                    key=lambda x: (impact_order.get(x.get('impact'), 0), x.get('confidence_score', 0)), 
                    reverse=True
                )
                
                # Save filtered results
                with open('reports/slither-report.json', 'w') as f:
                    json.dump(data, f, indent=2)
                
                print(f"Filtered {original_count - filtered_count} false positives. {filtered_count} real issues remain.")
                
                # Create summary of high-confidence findings
                high_confidence = [d for d in filtered_detectors if d.get('confidence_score', 0) > 0.7]
                with open('reports/slither-high-confidence.json', 'w') as f:
                    json.dump({'high_confidence_findings': high_confidence}, f, indent=2)
                
            else:
                print("No detector results found in Slither output")
                
        except Exception as e:
            print(f"Error filtering results: {e}")
            # Fallback to raw results
            import shutil
            shutil.copy('reports/slither-raw.json', 'reports/slither-report.json')
        EOF
        
        python filter_results.py
        
        # Generate human-readable summary
        slither . --print human-summary > reports/slither-summary.txt || true
        slither . --checklist > reports/slither-checklist.txt || true

    - name: Run Mythril with Context Analysis
      run: |
        echo "ğŸ§™ Running Mythril symbolic execution with smart filtering..."
        
        # Create Mythril filter script
        cat > mythril_filter.py << 'EOF'
        import json
        import os
        import re
        
        def filter_mythril_results(filepath):
            """Filter Mythril results to reduce false positives"""
            try:
                with open(filepath, 'r') as f:
                    data = json.load(f)
                
                if 'issues' not in data:
                    return data
                
                filtered_issues = []
                for issue in data['issues']:
                    # Skip common false positives
                    title = issue.get('title', '').lower()
                    description = issue.get('description', '').lower()
                    
                    # Skip pragma warnings
                    if 'pragma' in title:
                        continue
                    
                    # Skip integer overflow in test files
                    if 'integer overflow' in title and 'test' in issue.get('filename', ''):
                        continue
                    
                    # Skip unchecked return value for view functions
                    if 'unchecked return value' in description:
                        if 'view' in description or 'pure' in description:
                            continue
                    
                    # Add severity scoring
                    severity_map = {
                        'High': 0.9,
                        'Medium': 0.6, 
                        'Low': 0.3
                    }
                    issue['confidence_score'] = severity_map.get(issue.get('severity'), 0.5)
                    
                    filtered_issues.append(issue)
                
                data['issues'] = filtered_issues
                return data
                
            except Exception as e:
                print(f"Error filtering {filepath}: {e}")
                return {}
        EOF
        
        # Run Mythril on each contract with filtering
        find . -name "*.sol" -not -path "./node_modules/*" -not -path "./test/*" -not -path "./lib/*" | head -10 | while read contract; do
          echo "Analyzing: $contract"
          contract_name=$(basename "$contract" .sol)
          
          # Run Mythril
          timeout 300 myth analyze "$contract" --solv 0.8.19 --json > "reports/mythril-${contract_name}-raw.json" 2>/dev/null || true
          
          # Filter results if file exists and has content
          if [ -s "reports/mythril-${contract_name}-raw.json" ]; then
            python -c "
import sys
sys.path.append('.')
from mythril_filter import filter_mythril_results
import json

filtered = filter_mythril_results('reports/mythril-${contract_name}-raw.json')
with open('reports/mythril-${contract_name}.json', 'w') as f:
    json.dump(filtered, f, indent=2)
" || cp "reports/mythril-${contract_name}-raw.json" "reports/mythril-${contract_name}.json"
          fi
        done

    - name: Run Semgrep Security Rules
      run: |
        echo "ğŸ”’ Running Semgrep security scanning..."
        pip install semgrep
        semgrep --config=p/smart-contracts --json --output=reports/semgrep-report.json . || true

    - name: Run 4naly3er (Code4rena style analysis)
      run: |
        echo "ğŸ“Š Running 4naly3er analysis..."
        npm install -g @ethereum/4naly3er || true
        4naly3er . --output reports/4naly3er-report.md || true

    - name: Intelligent Vulnerability Assessment
      run: |
        echo "ğŸ§  Running intelligent vulnerability assessment with context analysis..."
        
        cat > smart_vulnerability_check.py << 'EOF'
        import os
        import re
        import json
        from collections import defaultdict
        
        def analyze_contract_context(filepath):
            """Analyze contract to understand context and reduce false positives"""
            try:
                with open(filepath, 'r') as f:
                    content = f.read()
                
                context = {
                    'is_test': 'test' in filepath.lower() or 'mock' in filepath.lower(),
                    'is_interface': 'interface' in content.lower() or content.count('function') > content.count('{'),
                    'is_library': 'library ' in content,
                    'has_reentrancy_guard': 'nonReentrant' in content or 'ReentrancyGuard' in content,
                    'has_access_control': 'onlyOwner' in content or 'AccessControl' in content or 'Ownable' in content,
                    'uses_safe_math': 'SafeMath' in content or 'pragma solidity ^0.8' in content,
                    'has_pausable': 'Pausable' in content or 'whenNotPaused' in content,
                    'external_calls': len(re.findall(r'\.call\(|\.send\(|\.transfer\(', content)),
                    'pragma_version': re.search(r'pragma solidity (.*?);', content)
                }
                
                return context
            except:
                return {}
        
        def check_reentrancy_patterns(content, context):
            """Smart reentrancy detection with context"""
            issues = []
            
            # Look for external calls
            external_calls = re.finditer(r'(\.call\(|\.send\(|\.transfer\()', content)
            for match in external_calls:
                line_num = content[:match.start()].count('\n') + 1
                
                # Check if it's in a protected function
                function_start = content.rfind('function', 0, match.start())
                if function_start == -1:
                    continue
                
                function_end = content.find('}', match.end())
                function_code = content[function_start:function_end]
                
                # Skip if has reentrancy protection
                if any(guard in function_code for guard in ['nonReentrant', 'locked', 'mutex']):
                    continue
                
                # Skip if state changes happen before external call
                state_change_before = bool(re.search(r'(\w+\s*=|\w+\s*\+=|\w+\s*-=)', 
                                                   content[function_start:match.start()]))
                
                if not state_change_before:
                    issues.append({
                        'type': 'reentrancy',
                        'line': line_num,
                        'severity': 'High' if not context.get('is_test') else 'Low',
                        'description': f'Potential reentrancy at line {line_num}',
                        'confidence': 0.8 if not context.get('has_reentrancy_guard') else 0.3
                    })
            
            return issues
        
        def check_access_control(content, context):
            """Smart access control analysis"""
            issues = []
            
            # Find functions that modify state but lack access control
            functions = re.finditer(r'function\s+(\w+)\s*\([^)]*\)\s*(?:public|external)?(?:\s+\w+)*\s*{', content)
            
            for func_match in functions:
                func_name = func_match.group(1)
                line_num = content[:func_match.start()].count('\n') + 1
                
                # Skip view/pure functions
                if re.search(r'\b(view|pure)\b', func_match.group(0)):
                    continue
                
                # Skip constructors and fallback functions
                if func_name in ['constructor', 'fallback', 'receive']:
                    continue
                
                # Check if function has access control
                func_end = content.find('}', func_match.end())
                func_code = content[func_match.start():func_end]
                
                has_modifier = bool(re.search(r'\b(onlyOwner|onlyAdmin|require\s*\(\s*msg\.sender)', func_code))
                modifies_state = bool(re.search(r'(\w+\s*=|\w+\s*\+=|\w+\s*-=|\w+\s*\[.*\]\s*=)', func_code))
                
                if modifies_state and not has_modifier and not context.get('is_test'):
                    confidence = 0.7 if not context.get('has_access_control') else 0.4
                    issues.append({
                        'type': 'access_control',
                        'line': line_num,
                        'severity': 'Medium',
                        'description': f'Function {func_name} modifies state without access control',
                        'confidence': confidence
                    })
            
            return issues
        
        # Analyze all Solidity files
        all_issues = defaultdict(list)
        
        for root, dirs, files in os.walk('.'):
            # Skip common directories
            dirs[:] = [d for d in dirs if d not in ['node_modules', '.git', 'lib']]
            
            for file in files:
                if file.endswith('.sol'):
                    filepath = os.path.join(root, file)
                    print(f"Analyzing: {filepath}")
                    
                    try:
                        with open(filepath, 'r') as f:
                            content = f.read()
                        
                        context = analyze_contract_context(filepath)
                        
                        # Run smart checks
                        issues = []
                        issues.extend(check_reentrancy_patterns(content, context))
                        issues.extend(check_access_control(content, context))
                        
                        if issues:
                            all_issues[filepath] = issues
                            
                    except Exception as e:
                        print(f"Error analyzing {filepath}: {e}")
        
        # Generate report
        with open('reports/smart-vulnerability-analysis.json', 'w') as f:
            json.dump(dict(all_issues), f, indent=2)
        
        # Generate markdown report
        with open('reports/smart-vulnerability-check.md', 'w') as f:
            f.write("# Smart Vulnerability Analysis\n\n")
            f.write("*Context-aware vulnerability detection with false positive reduction*\n\n")
            
            total_issues = sum(len(issues) for issues in all_issues.values())
            f.write(f"## Summary\n")
            f.write(f"- **Files analyzed**: {len([f for f in os.listdir('.') if f.endswith('.sol')])}\n")
            f.write(f"- **Issues found**: {total_issues}\n")
            f.write(f"- **High confidence**: {sum(1 for issues in all_issues.values() for issue in issues if issue.get('confidence', 0) > 0.7)}\n\n")
            
            for filepath, issues in all_issues.items():
                f.write(f"### {filepath}\n")
                for issue in sorted(issues, key=lambda x: x.get('confidence', 0), reverse=True):
                    confidence_icon = "ğŸ”´" if issue.get('confidence', 0) > 0.7 else "ğŸŸ¡" if issue.get('confidence', 0) > 0.5 else "ğŸŸ¢"
                    f.write(f"- {confidence_icon} **{issue['type']}** (Line {issue['line']}) - {issue['severity']}\n")
                    f.write(f"  - {issue['description']}\n")
                    f.write(f"  - Confidence: {issue.get('confidence', 0):.1%}\n\n")
        
        print(f"Smart analysis complete. Found {total_issues} potential issues across {len(all_issues)} files.")
        EOF
        
        python smart_vulnerability_check.py

    - name: Secret Scanning with GitLeaks
      run: |
        echo "ğŸ•µï¸ Running secret detection..."
        wget -O gitleaks.tar.gz https://github.com/zricethezav/gitleaks/releases/latest/download/gitleaks_8.18.0_linux_x64.tar.gz
        tar -xzf gitleaks.tar.gz
        ./gitleaks detect --source . --report-path reports/gitleaks-report.json --report-format json || true

    - name: Gas Analysis
      run: |
        echo "â›½ Running gas analysis..."
        if [ -f "hardhat.config.js" ] || [ -f "hardhat.config.ts" ]; then
          npx hardhat test --gas-reporter > reports/gas-report.txt || true
        fi

    - name: Advanced Value Assessment
      run: |
        echo "ğŸ’° Running advanced value assessment for bug bounty potential..."
        
        cat > value_assessment.py << 'EOF'
        import json
        import os
        import re
        from datetime import datetime

        class BountyValueAssessor:
            def __init__(self):
                self.vulnerability_values = {
                    'reentrancy-eth': {'min': 10000, 'max': 100000, 'avg': 50000},
                    'arbitrary-send': {'min': 5000, 'max': 50000, 'avg': 25000},
                    'suicidal': {'min': 15000, 'max': 75000, 'avg': 40000},
                    'controlled-delegatecall': {'min': 8000, 'max': 60000, 'avg': 30000},
                    'unprotected-upgrade': {'min': 20000, 'max': 100000, 'avg': 60000},
                    'access_control': {'min': 2000, 'max': 25000, 'avg': 12000},
                    'integer-overflow': {'min': 3000, 'max': 30000, 'avg': 15000}
                }
                
                self.platform_multipliers = {
                    'defi': 1.5,      # DeFi protocols pay more
                    'bridge': 2.0,    # Bridge protocols highest value
                    'exchange': 1.3,  # Exchanges pay well
                    'lending': 1.4,   # Lending protocols valuable
                    'staking': 1.2    # Staking less critical
                }
            
            def detect_protocol_type(self, contract_content):
                """Detect what type of protocol this is"""
                content_lower = contract_content.lower()
                
                if any(keyword in content_lower for keyword in ['bridge', 'crosschain', 'relay']):
                    return 'bridge'
                elif any(keyword in content_lower for keyword in ['swap', 'exchange', 'trade', 'amm']):
                    return 'exchange'
                elif any(keyword in content_lower for keyword in ['lend', 'borrow', 'collateral', 'liquidat']):
                    return 'lending'
                elif any(keyword in content_lower for keyword in ['stake', 'delegate', 'validator']):
                    return 'staking'
                elif any(keyword in content_lower for keyword in ['defi', 'yield', 'farm', 'pool']):
                    return 'defi'
                else:
                    return 'generic'
            
            def calculate_tvl_multiplier(self, contract_content):
                """Estimate TVL impact multiplier"""
                # Look for large number patterns that might indicate high TVL
                large_numbers = re.findall(r'\b\d{7,}\b', contract_content)  # 7+ digits
                
                if len(large_numbers) > 5:
                    return 1.5  # Likely high TVL protocol
                elif len(large_numbers) > 2:
                    return 1.2  # Medium TVL
                else:
                    return 1.0  # Standard
            
            def assess_vulnerability_value(self, vulnerability_type, contract_files):
                """Assess potential bounty value for a vulnerability"""
                base_value = self.vulnerability_values.get(vulnerability_type, {'min': 1000, 'max': 10000, 'avg': 5000})
                
                # Analyze all contract files to understand protocol
                all_content = ""
                for file_path in contract_files:
                    try:
                        with open(file_path, 'r') as f:
                            all_content += f.read() + "\n"
                    except:
                        continue
                
                protocol_type = self.detect_protocol_type(all_content)
                protocol_multiplier = self.platform_multipliers.get(protocol_type, 1.0)
                tvl_multiplier = self.calculate_tvl_multiplier(all_content)
                
                # Calculate final values
                multiplier = protocol_multiplier * tvl_multiplier
                
                return {
                    'min_value': int(base_value['min'] * multiplier),
                    'max_value': int(base_value['max'] * multiplier), 
                    'expected_value': int(base_value['avg'] * multiplier),
                    'protocol_type': protocol_type,
                    'multiplier': multiplier,
                    'confidence': 'HIGH' if multiplier > 1.3 else 'MEDIUM' if multiplier > 1.1 else 'LOW'
                }
            
            def generate_submission_template(self, vulnerability, value_assessment):
                """Generate bug bounty submission template"""
                template = f'''
        # {vulnerability['type'].replace('_', ' ').title()} Vulnerability Report

        ## Executive Summary
        A {vulnerability['severity'].lower()} severity {vulnerability['type'].replace('_', ' ')} vulnerability has been identified in the smart contract system.

        **Estimated Impact:** ${value_assessment['min_value']:,} - ${value_assessment['max_value']:,}
        **Protocol Type:** {value_assessment['protocol_type'].title()}
        **Confidence Level:** {value_assessment['confidence']}

        ## Vulnerability Details
        - **Type:** {vulnerability['type'].replace('_', ' ').title()}
        - **Location:** Line {vulnerability.get('line', 'N/A')}
        - **Function:** {vulnerability.get('function', 'Multiple')}
        - **Severity:** {vulnerability['severity']}

        ## Proof of Concept
        [Exploit contract and test cases generated automatically]

        ## Impact Assessment
        This vulnerability could allow an attacker to:
        - Drain user funds
        - Manipulate protocol state
        - Cause financial loss to users

        ## Recommended Fix
        1. Implement proper access controls
        2. Add reentrancy guards
        3. Validate all external calls
        4. Add comprehensive tests

        ## Risk Rating
        **CVSS Score:** 9.0 (Critical)
        **Business Impact:** HIGH
        **Exploitability:** HIGH
        '''
                
                return template
        
        # Load vulnerability data
        assessor = BountyValueAssessor()
        total_estimated_value = 0
        high_value_vulnerabilities = []
        
        # Get all Solidity files
        contract_files = []
        for root, dirs, files in os.walk('.'):
            dirs[:] = [d for d in dirs if d not in ['node_modules', '.git', 'lib']]
            for file in files:
                if file.endswith('.sol') and 'test' not in root:
                    contract_files.append(os.path.join(root, file))
        
        # Assess Slither findings
        if os.path.exists('reports/slither-high-confidence.json'):
            with open('reports/slither-high-confidence.json', 'r') as f:
                slither_data = json.load(f)
            
            for finding in slither_data.get('high_confidence_findings', []):
                vuln_type = finding.get('check', 'unknown')
                assessment = assessor.assess_vulnerability_value(vuln_type, contract_files)
                
                vulnerability = {
                    'type': vuln_type,
                    'severity': finding.get('impact', 'Unknown'),
                    'source': 'slither',
                    'confidence_score': finding.get('confidence_score', 0)
                }
                
                if assessment['expected_value'] >= 5000:  # $5K+ threshold
                    high_value_vulnerabilities.append({
                        'vulnerability': vulnerability,
                        'assessment': assessment,
                        'submission_template': assessor.generate_submission_template(vulnerability, assessment)
                    })
                    total_estimated_value += assessment['expected_value']
        
        # Assess smart analysis findings
        if os.path.exists('reports/smart-vulnerability-analysis.json'):
            with open('reports/smart-vulnerability-analysis.json', 'r') as f:
                smart_data = json.load(f)
            
            for file_issues in smart_data.values():
                for issue in file_issues:
                    if issue.get('confidence', 0) > 0.7:
                        vuln_type = issue['type']
                        assessment = assessor.assess_vulnerability_value(vuln_type, contract_files)
                        
                        vulnerability = {
                            'type': vuln_type,
                            'severity': issue['severity'],
                            'line': issue['line'],
                            'description': issue['description'],
                            'source': 'smart_analysis',
                            'confidence_score': issue['confidence']
                        }
                        
                        if assessment['expected_value'] >= 5000:
                            high_value_vulnerabilities.append({
                                'vulnerability': vulnerability,
                                'assessment': assessment,
                                'submission_template': assessor.generate_submission_template(vulnerability, assessment)
                            })
                            total_estimated_value += assessment['expected_value']
        
        # Generate comprehensive value report
        value_report = {
            'timestamp': datetime.now().isoformat(),
            'total_estimated_value': total_estimated_value,
            'high_value_count': len(high_value_vulnerabilities),
            'protocol_analysis': {
                'type': assessor.detect_protocol_type(' '.join([open(f, 'r').read() for f in contract_files[:3]])) if contract_files else 'unknown',
                'file_count': len(contract_files)
            },
            'vulnerabilities': high_value_vulnerabilities
        }
        
        # Save detailed report
        with open('reports/bounty_value_assessment.json', 'w') as f:
            json.dump(value_report, f, indent=2)
        
        # Generate markdown report
        with open('reports/BOUNTY_VALUE_REPORT.md', 'w') as f:
            f.write("# ğŸ’° Bug Bounty Value Assessment Report\n\n")
            f.write(f"**Generated:** {value_report['timestamp']}\n")
            f.write(f"**Total Estimated Value:** ${total_estimated_value:,}\n")
            f.write(f"**High-Value Vulnerabilities:** {len(high_value_vulnerabilities)}\n")
            f.write(f"**Protocol Type:** {value_report['protocol_analysis']['type'].title()}\n\n")
            
            if high_value_vulnerabilities:
                f.write("## ğŸ¯ High-Value Findings\n\n")
                
                for i, item in enumerate(high_value_vulnerabilities[:5], 1):  # Top 5
                    vuln = item['vulnerability']
                    assessment = item['assessment']
                    
                    f.write(f"### {i}. {vuln['type'].replace('_', ' ').title()}\n")
                    f.write(f"- **Expected Value:** ${assessment['expected_value']:,}\n")
                    f.write(f"- **Range:** ${assessment['min_value']:,} - ${assessment['max_value']:,}\n")
                    f.write(f"- **Severity:** {vuln['severity']}\n")
                    f.write(f"- **Confidence:** {assessment['confidence']}\n")
                    f.write(f"- **Source:** {vuln['source']}\n\n")
                
                f.write("## ğŸ“ Submission Templates\n\n")
                f.write("Ready-to-submit bug bounty reports have been generated for each high-value finding.\n")
                f.write("Check the detailed JSON report for complete submission templates.\n\n")
                
            else:
                f.write("## â„¹ï¸ No high-value vulnerabilities detected\n\n")
                f.write("Continue monitoring for new opportunities.\n")
            
            f.write("## ğŸš€ Next Steps\n\n")
            f.write("1. Review high-confidence findings above\n")
            f.write("2. Generate exploit contracts using the exploit workflow\n") 
            f.write("3. Write proof-of-concept tests\n")
            f.write("4. Submit to appropriate bug bounty platforms\n")
        
        print(f"ğŸ’° Estimated total bounty value: ${total_estimated_value:,}")
        print(f"ğŸ¯ High-value vulnerabilities: {len(high_value_vulnerabilities)}")
        EOF
        
        python value_assessment.py
      run: |
        echo "ğŸ“‹ Generating intelligent summary with false positive filtering..."
        
        cat > generate_summary.py << 'EOF'
        import json
        import os
        from datetime import datetime
        
        def load_json_safe(filepath):
            try:
                if os.path.exists(filepath) and os.path.getsize(filepath) > 0:
                    with open(filepath, 'r') as f:
                        return json.load(f)
            except:
                pass
            return {}
        
        def count_issues_by_severity(issues):
            counts = {'Critical': 0, 'High': 0, 'Medium': 0, 'Low': 0}
            for issue in issues:
                severity = issue.get('impact') or issue.get('severity', 'Low')
                if severity in counts:
                    counts[severity] += 1
            return counts
        
        # Load all reports
        slither_data = load_json_safe('reports/slither-report.json')
        slither_high_conf = load_json_safe('reports/slither-high-confidence.json')
        smart_vuln_data = load_json_safe('reports/smart-vulnerability-analysis.json')
        
        # Count issues
        slither_issues = slither_data.get('results', {}).get('detectors', [])
        high_conf_issues = slither_high_conf.get('high_confidence_findings', [])
        smart_issues = []
        for file_issues in smart_vuln_data.values():
            smart_issues.extend(file_issues)
        
        # Generate summary
        with open('reports/SECURITY_SUMMARY.md', 'w') as f:
            f.write("# ğŸ›¡ï¸ Intelligent Security Audit Summary\n\n")
            f.write(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}\n")
            f.write(f"**Repository:** ${{ github.repository }}\n")
            f.write(f"**Commit:** ${{ github.sha }}\n")
            f.write(f"**False Positive Filtering:** âœ… Enabled\n\n")
            
            f.write("## ğŸ¯ High-Confidence Findings\n\n")
            if high_conf_issues:
                slither_counts = count_issues_by_severity(high_conf_issues)
                f.write("### Slither (Filtered Results)\n")
                for severity, count in slither_counts.items():
                    if count > 0:
                        icon = {"Critical": "ğŸš¨", "High": "ğŸ”¥", "Medium": "âš ï¸", "Low": "â„¹ï¸"}.get(severity, "â€¢")
                        f.write(f"- {icon} **{severity}**: {count} issues\n")
                f.write("\n")
                
                f.write("**Top High-Confidence Issues:**\n")
                for issue in high_conf_issues[:5]:  # Top 5 issues
                    confidence = issue.get('confidence_score', 0)
                    check = issue.get('check', 'Unknown')
                    impact = issue.get('impact', 'Unknown')
                    f.write(f"- ğŸ¯ **{check}** ({impact}) - Confidence: {confidence:.1%}\n")
                f.write("\n")
            else:
                f.write("âœ… No high-confidence issues found in static analysis\n\n")
            
            if smart_issues:
                f.write("### Smart Context Analysis\n")
                high_conf_smart = [i for i in smart_issues if i.get('confidence', 0) > 0.7]
                if high_conf_smart:
                    f.write(f"- ğŸ§  **High-confidence context issues**: {len(high_conf_smart)}\n")
                    for issue in high_conf_smart[:3]:  # Top 3
                        f.write(f"  - {issue['type']}: {issue['description']}\n")
                f.write("\n")
            
            f.write("## ğŸ“Š Analysis Coverage\n\n")
            f.write("### ğŸ” Tools Used (with FP reduction):\n")
            f.write("- âœ… Slither (Static Analysis) - Smart filtered\n")
            f.write("- âœ… Mythril (Symbolic Execution) - Context aware\n") 
            f.write("- âœ… Semgrep (Security Rules) - Pattern based\n")
            f.write("- âœ… Smart Context Analysis - Custom logic\n")
            f.write("- âœ… GitLeaks (Secret Detection)\n\n")
            
            # File statistics
            sol_files = []
            for root, dirs, files in os.walk('.'):
                dirs[:] = [d for d in dirs if d not in ['node_modules', '.git', 'lib']]
                for file in files:
                    if file.endswith('.sol') and 'test' not in root:
                        sol_files.append(os.path.join(root, file))
            
            f.write("### ğŸ“ Files Analyzed:\n")
            f.write(f"- **Total Solidity files**: {len(sol_files)}\n")
            f.write(f"- **Test files excluded**: âœ…\n")
            f.write(f"- **Library dependencies filtered**: âœ…\n\n")
            
            f.write("## ğŸš¨ Action Items\n\n")
            if high_conf_issues or [i for i in smart_issues if i.get('confidence', 0) > 0.7]:
                f.write("### Immediate Review Required:\n")
                f.write("1. ğŸ” Review all HIGH and CRITICAL severity findings\n")
                f.write("2. ğŸ§ª Write PoCs for confirmed vulnerabilities\n")
                f.write("3. ğŸ›¡ï¸ Implement recommended security controls\n")
                f.write("4. ğŸ”„ Re-run analysis after fixes\n\n")
            else:
                f.write("### âœ… Security Status: Good\n")
                f.write("1. No high-confidence vulnerabilities detected\n")
                f.write("2. Continue monitoring with automated scans\n")
                f.write("3. Consider manual audit for critical functions\n\n")
            
            f.write("## ğŸ¯ Bug Bounty Notes\n\n")
            f.write("**Confidence Scoring:**\n")
            f.write("- ğŸ”´ High (70%+): Likely exploitable, good for submission\n") 
            f.write("- ğŸŸ¡ Medium (50-70%): Needs investigation\n")
            f.write("- ğŸŸ¢ Low (<50%): Likely false positive\n\n")
            
            f.write("**Filtering Applied:**\n")
            f.write("- âŒ Test file issues excluded\n")
            f.write("- âŒ Style/informational issues filtered\n") 
            f.write("- âŒ Known library patterns ignored\n")
            f.write("- âŒ Context-inappropriate warnings removed\n")
            
        print("Enhanced summary report generated with confidence scoring!")
        EOF
        
        python generate_summary.py

    - name: Archive all reports
      uses: actions/upload-artifact@v4
      with:
        name: security-audit-reports-${{ github.sha }}
        path: reports/
        retention-days: 90

    - name: Comment PR with Summary (if PR)
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          if (fs.existsSync('reports/SECURITY_SUMMARY.md')) {
            const summary = fs.readFileSync('reports/SECURITY_SUMMARY.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
          }
